# -*- coding: utf-8 -*-
"""DeepLearningModel_+ BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O8tojOgLCIqjAyamo8Dbtlzz55JqkA6-
"""

from google.colab import drive
drive.mount("/content/gdrive")

import sys
sys.path.append('/content/gdrive/MyDrive/aml_fp/')

import json
import csv
import pandas as pd
import sklearn
import numpy as np
import tensorflow as tf
import keras
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from keras.losses import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import tensorflow.keras.backend as K

#with open('/content/gdrive/MyDrive/aml_fp/embedding/train_small_embeddings.json') as json_file:
#    embeddings = json.load(json_file)

# with open('/content/gdrive/MyDrive/4995/aml_fp/embedding/train_small_embeddings.json') as json_file_train:
#    embeddings_train = json.load(json_file_train)

# w2v_train=pd.read_csv("/content/gdrive/MyDrive/aml_fp/X_train_150_w2v")
# w2v_test=pd.read_csv("/content/gdrive/MyDrive/aml_fp/X_test_150_w2v")
# print(w2v_train.shape)
# print(w2v_test.shape)

# tfidf_train=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_train_tfidf.csv")
# tfidf_test=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_test_tfidf.csv")
# print(tfidf_train.shape)
# print(tfidf_test.shape)

bert_train = pd.read_json('/content/gdrive/MyDrive/aml_fp/embedding/train_small_embeddings.json')
bert_train = bert_train.drop([0]).reset_index(drop=True)
bert_test = pd.read_json('/content/gdrive/MyDrive/4995/test_embeddings_new.json')
print(bert_train.shape)
print(bert_test.shape)

category_train=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_train_category.csv")
category_test=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_test_category.csv")
print(category_train.shape)
print(category_test.shape)

#select feature
X_train=[category_train.iloc[:,1:7],bert_train]
X_train=pd.concat(X_train,axis=1)
X_test=[category_test.iloc[:,1:7], bert_test]
X_test=pd.concat(X_test,axis=1)
print(X_train.shape)
print(X_test.shape)

y_train = category_train["price"]
y_test =  category_test["price"]

y_train_log = np.log(category_train["price"]+1)
y_test_log = np.log(category_test["price"]+1)
print(len(y_test))

y_test

# embeddings_train =0
# X_train = 0

# category_train=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_train_category.csv")
# category_test=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_test_category.csv")
# print(category_train.shape)
# print(category_test.shape)

# tfidf_train=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_train_tfidf.csv")
# tfidf_test=pd.read_csv("/content/gdrive/MyDrive/aml_fp/other_features/df_test_tfidf.csv")
# print(tfidf_train.shape)
# print(tfidf_test.shape)

# X_train=[category_train.iloc[:,1:7],tfidf_train.iloc[:,1:]]
# X_train=pd.concat(X_train,axis=1)
# y_train=category_train["price"]
# X_test=[category_test.iloc[:,1:7],tfidf_test.iloc[:,1:]]
# X_test=pd.concat(X_test,axis=1)
# y_test=category_test["price"]
# print(X_train.shape)
# print(X_test.shape)

# category_train=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/other_features/df_train_category.csv")
# category_test=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/other_features/df_test_category.csv")
# print(category_train.shape)
# print(category_test.shape)

# tfidf_train=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/other_features/df_train_tfidf.csv")
# tfidf_test=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/other_features/df_test_tfidf.csv")
# print(tfidf_train.shape)
# print(tfidf_test.shape)

# X_train=[category_train.iloc[:,1:7],tfidf_train.iloc[:,1:]]
# X_train=pd.concat(X_train,axis=1)
# y_train=category_train["price"]
# X_test=[category_test.iloc[:,1:7],tfidf_test.iloc[:,1:]]
# X_test=pd.concat(X_test,axis=1)
# y_test=category_test["price"]
# print(X_train.shape)
# print(X_test.shape)

# X_train=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/X_train_150_w2v")
# y_train=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/y_train_150_w2v")
# X_test=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/X_test_150_w2v")
# y_test=pd.read_csv("/content/gdrive/MyDrive/4995/aml_fp/y_test_150_w2v")

# y_train=y_train.iloc[:,1:]
# y_test=y_test.iloc[:,1:]

def root_mean_squared_log_error(y_true, y_pred):
    msle = tf.keras.losses.MeanSquaredLogarithmicError()
    return K.sqrt(msle(y_true, y_pred))

model = Sequential()
model.add(Dense(1024, input_dim=X_train.shape[1],  activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))
# Compile model
optimizer = tf.keras.optimizers.Adam(lr=0.00001)
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredError()])
model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=[tf.keras.metrics.MeanSquaredLogarithmicError(name="mean_squared_logarithmic_error")])
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredLogarithmicError(name="mean_squared_logarithmic_error")])
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])
model.fit(X_train,y_train, validation_split=0.2, batch_size=64, epochs=30)
model.evaluate(X_test,y_test)

"""### logprice"""

model_lg = Sequential()
model_lg.add(Dense(1024, input_dim=X_train.shape[1],  activation='relu'))
model_lg.add(Dense(512, activation='relu'))
model_lg.add(Dense(256, activation='relu'))
model_lg.add(Dense(128, activation='relu'))
model_lg.add(Dense(64, activation='relu'))
model_lg.add(Dense(32, activation='relu'))
model_lg.add(Dense(1))
# Compile model
optimizer = tf.keras.optimizers.Adam(lr=0.00001)
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredError()])
model_lg.compile(loss='mean_squared_error', optimizer=optimizer,metrics=[tf.keras.metrics.MeanSquaredLogarithmicError(name="mean_squared_logarithmic_error")])
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredLogarithmicError(name="mean_squared_logarithmic_error")])
#model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])
model_lg.fit(X_train,y_train_log, validation_split=0.2, batch_size=64, epochs=10)
model_lg.evaluate(X_test,y_test_log)