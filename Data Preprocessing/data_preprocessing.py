# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rIgjZhtT9PQHRYazcyB2DjMyG7MURnnn
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler,OrdinalEncoder,OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer
from sklearn.neighbors import KNeighborsClassifier
from nltk.corpus import stopwords
from category_encoders import TargetEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
import gensim
from gensim.models import Word2Vec
import re

df_train = pd.read_csv("./train.csv",sep=',', nrows = 200000)
df_test = pd.read_csv("./test.csv",sep=',')

def split_cat(text):
    try: return text.split("/")
    except: return ("No Category", "No Category", "No Category")

df_train['main_category'], df_train['subcategory_1'], df_train['subcategory_2'] = zip(*df_train['category_name'].apply(lambda x: split_cat(x)))
df_test['main_category'], df_test['subcategory_1'], df_test['subcategory_2'] = zip(*df_test['category_name'].apply(lambda x: split_cat(x)))

"""## Part1 Feature Construction

### 1.1 Category Feature
"""

## updated_brand_name
te = TargetEncoder(cols = ["updated_brand_name"]).fit(df_train,df_train["price"])
df_train['brand_name_te'] = te.transform(df_train)['updated_brand_name']
df_test['brand_name_te'] = te.transform(df_test)['updated_brand_name']

## shipping
te = TargetEncoder(cols = ["shipping"]).fit(df_train,df_train["price"])
df_train['shipping_te'] = te.transform(df_train)['shipping']
df_test['shipping_te'] = te.transform(df_test)['shipping']

## item_conditional_id
te = TargetEncoder(cols = ["item_condition_id"]).fit(df_train,df_train["price"])
df_train['item_condition_id_te'] = te.transform(df_train)['item_condition_id']
df_test['item_condition_id_te'] = te.transform(df_test)['item_condition_id']

## update 3-level categories
#main category
te = TargetEncoder(cols = ["main_category"]).fit(df_train,df_train["price"])
df_train['main_category_te'] = te.transform(df_train)['main_category']
df_test['main_category_te'] = te.transform(df_test)['main_category']
#subcategory_1
te = TargetEncoder(cols = ["subcategory_1"]).fit(df_train,df_train["price"])
df_train['subcategory_1_te'] = te.transform(df_train)['subcategory_1']
df_test['subcategory_1_te'] = te.transform(df_test)['subcategory_1']
#subcategory_2
te = TargetEncoder(cols = ["subcategory_2"]).fit(df_train,df_train["price"])
df_train['subcategory_2_te'] = te.transform(df_train)['subcategory_2']
df_test['subcategory_2_te'] = te.transform(df_test)['subcategory_2']

category_features_list = ['brand_name_te','shipping_te', 'item_condition_id_te', 
                          'main_category_te', 'subcategory_1_te', 'subcategory_2_te', 'price']

df_train_category = df_train[category_features_list]
df_test_category = df_test[category_features_list]

df_train_category.to_csv('./df_train_category.csv')
df_test_category.to_csv('./df_test_category.csv')

df_train_category

"""### 1.2 Text Feature

#### 1.2.1 TF-IDF
"""

vector = TfidfVectorizer()
train_tfidf = vector.fit_transform(df_train['item_description'].apply(lambda x: np.str_(x)))
test_tfidf = vector.transform(df_test['item_description'].apply(lambda x: np.str_(x)))

df_train['item_description']

test_tfidf.shape

#remove stopwords
stop_words = set(stopwords.words('english'))
tfidf = TfidfVectorizer(stop_words=stop_words,max_features=400)
train_tfidf = tfidf.fit_transform(df_train['item_description'].apply(lambda x: np.str_(x)))
test_tfidf = tfidf.transform(df_test['item_description'].apply(lambda x: np.str_(x)))

len(tfidf.vocabulary_)

train_tfidf.shape

# # from sklearn.feature_selection import SelectKBest,f_regression
# select_model = SelectKBest(f_regression, k=1000)
# train_tfidf_1000 = select_model.fit_transform(train_tfidf, df_train['price'])
# test_tfidf_1000 = select_model.transform(test_tfidf)

column_name = []
for i in range(400):
    column_name.append("tfidf_"+ str(i))

df_tfidf_train = pd.DataFrame(train_tfidf.todense(), columns = column_name)
df_tfidf_test = pd.DataFrame(test_tfidf.todense(),columns = column_name)

df_tfidf_train.to_csv('./df_train_tfidf.csv')
df_tfidf_test.to_csv('./df_test_tfidf.csv')

df_tfidf_test

"""#### 1.2.2 Word2Vec"""

from nltk.corpus import stopwords
stopwords_set = set(stopwords.words('english'))

sentences = []
for single_des in df_train["item_description"].values:
    for s in re.split("\.", str(single_des)):
        if len(s) > 2:
            sentence = []
            for word in s.split(" "):
                if len(word)>1 and word not in stopwords_set:
                    sentence.append(word.strip().lower())
            sentences.append(sentence)

VECTOR_SIZE = 150
model = Word2Vec(sentences, vector_size=VECTOR_SIZE, window=5, min_count=5, workers=4)

model.wv.most_similar('computer', topn=10)

words_vob = list(model.wv.index_to_key)
w2v_vector_train = np.zeros((df_train.shape[0], VECTOR_SIZE))

for i in range(df_train.shape[0]):
    word_list = str(df_train['item_description'][i]).split(" ")
    single_vector = np.zeros(VECTOR_SIZE)
    cnt = 0
    for word in word_list:
        word = word.strip().lower()
        if word in words_vob:
            single_vector += model.wv[word]
            cnt += 1
    if cnt > 0:
        w2v_vector_train[i] = single_vector / cnt

w2v_vector_test = np.zeros((df_test.shape[0], VECTOR_SIZE))

for i in range(df_test.shape[0]):
    word_list = str(df_train['item_description'][i]).split(" ")
    single_vector = np.zeros(VECTOR_SIZE)
    cnt = 0
    for word in word_list:
        word = word.strip().lower()
        if word in words_vob:
            single_vector += model.wv[word]
            cnt += 1
    if cnt > 0:
        w2v_vector_test[i] = single_vector / cnt

column_name = []
for i in range(VECTOR_SIZE):
    column_name.append("w2v_"+ str(i))

df_w2v_train = pd.DataFrame(w2v_vector_train, columns = column_name)
df_w2v_test = pd.DataFrame(w2v_vector_test, columns = column_name)

df_w2v_train.to_csv('./df_train_w2v.csv')
df_w2v_test.to_csv('./df_test_w2v.csv')

"""#### 1.2.3 Bert"""